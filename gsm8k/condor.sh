#!/bin/sh
export CUDA_VISIBLE_DEVICES=0
#/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --num_token 1 --max_value 1.0 --root_output_dir output_attn_clip_long --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128
/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 1 --max_value 0.2 --root_output_dir output_attn_clip_long1
/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 1 --max_value 0.3 --root_output_dir output_attn_clip_long1
/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 1 --max_value 0.4 --root_output_dir output_attn_clip_long1
#/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 1 --max_value 0.5 --root_output_dir output_attn_clip_long
/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 2 --max_value 0.2 --root_output_dir output_attn_clip_long1
/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 2 --max_value 0.3 --root_output_dir output_attn_clip_long1
/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 2 --max_value 0.4 --root_output_dir output_attn_clip_long1
/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 4 --max_value 0.2 --root_output_dir output_attn_clip_long1
/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 4 --max_value 0.3 --root_output_dir output_attn_clip_long1
/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 4 --max_value 0.4 --root_output_dir output_attn_clip_long1

#/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 8 --max_value 0.2 --root_output_dir output_attn_clip_long
#/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 8 --max_value 0.3 --root_output_dir output_attn_clip_long
#/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 8 --max_value 0.4 --root_output_dir output_attn_clip_long
#/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 16 --max_value 0.2 --root_output_dir output_attn_clip_long
#/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 16 --max_value 0.3 --root_output_dir output_attn_clip_long
#/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 16 --max_value 0.4 --root_output_dir output_attn_clip_long
#/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 32 --max_value 0.2 --root_output_dir output_attn_clip_long
#/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 32 --max_value 0.3 --root_output_dir output_attn_clip_long
#/home/yyu429/ENTER/envs/s5/bin/python3  eval_gsm8k_cot.py --model meta-llama/Llama-2-7b-hf --prompt_file lib_prompt/prompt_long_questions.txt --batch_size 3 --max_new_tokens 128 --num_token 32 --max_value 0.4 --root_output_dir output_attn_clip_long

